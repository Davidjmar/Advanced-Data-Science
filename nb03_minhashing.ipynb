{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3:  Minhashing\n",
    "***\n",
    "\n",
    "In this notebook we'll practice computing similarity exactly using Jaccard similarity, and try out minhashing as a means to estimate the Jaccard similarity in a more computationally efficient manner. \n",
    "\n",
    "We'll need Numpy and Pandas for this notebook, so let's load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be plotting using Matplotlib's Pyplot, so we can import that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:  Exact Similarities\n",
    "\n",
    "Suppose for a set of 5 friends, there are 10 movies that each person either has or has not seen. We can construct a synthetic set of data by generating a characteristic matrix of 0s and 1s for the friends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.65\n",
    "nrow = 10\n",
    "ncol = 5\n",
    "np.random.seed(2019)\n",
    "C = np.random.choice([1, 0], size=(nrow, ncol), p=[p, 1-p])\n",
    "dfC = pd.DataFrame(C, columns=['Anya','Bahati','Cyril','Dack','Eloise'])\n",
    "print(dfC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anya wants to see a movie with one of her friends, and for whatever reason is dead set on only seeing the movie with *exactly* one friend. She is a huge data science nerd, so she decides the most reasonable thing to do is to figure out which friend she is most similar to, as measured by their Jaccard similarity:\n",
    "$$sim(A,B) = \\dfrac{|A \\cap B|}{|A \\cup B|}$$\n",
    "\n",
    "First, let's directly compute the Jaccard similarity of Anya and each other person. The similarity between Anya and Bahati, for example, is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = \"Anya\"\n",
    "col2 = \"Bahati\"\n",
    "numer = np.sum((dfC[col1]==1) & (dfC[col2]==1))\n",
    "denom = np.sum((dfC[col1]==1) | (dfC[col2]==1))\n",
    "sim = numer/denom\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish off Anya's grueling and weird decision by computing the similarities between her and the other friends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like ???? is the lucky winner! And if Anya is feeling kind, maybe ???? can come too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:  Approximate Similarities\n",
    "\n",
    "The idea behind minhashing is that we want to estimate these similarities, since as the number of features and number of users grow, the computation becomes pretty wild pretty fast. Minhashing uses hash functions to simulate an actual permutations of the rows of our characteristic matrix. The use of hash functions is also a tool to save on computation because if we were to actually permute the rows of a billion+ entry matrix, it's going to take a while.\n",
    "\n",
    "Let's first convince ourselves that minhashing as a method for estimating similarity actually works. We'll do this by actually permuting the rows of our characteristic matrix. For each permutation, we then compute the elements of a row in our **signature matrix** as the first row for which each column has a nonzero element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of permutations to use in estimate\n",
    "nperm = 100\n",
    "\n",
    "# signature matrix\n",
    "Msig = np.zeros([nperm, len(dfC.columns)])\n",
    "\n",
    "# fill in signature matrix\n",
    "\n",
    "# do the first row on its own for illustration\n",
    "i = 0\n",
    "\n",
    "# random permutation of the rows\n",
    "np.random.seed(2019)\n",
    "rowperm = np.random.choice(range(len(dfC)), size=len(dfC), replace=False)\n",
    "dfPerm = dfC.iloc[rowperm,:] # the permuted matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the first 5 rows of the permuted characteristic matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPerm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we see that Anya's first 1 is in row 2, Bahati, Cyril and Dack are in row 1, and Eloise is in row 3. So the first row of the signature matrix (corresponding to this permutation) should be [2, 1, 1, 1, 3]. Let's do the computation and check our result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first spot where each column is a 1\n",
    "# (By convention, we start from row 1. Sorry Python :\\)\n",
    "\n",
    "# loop over the rows\n",
    "for k in range(len(dfPerm)):\n",
    "    # loop over the columns\n",
    "    for j in range(Msig.shape[1]):\n",
    "        # check if we found the first 1\n",
    "        if dfPerm.iloc[k,j]==1 and Msig[i,j]==0:\n",
    "            Msig[i,j] = k+1\n",
    "print(Msig[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! That's exactly what we were hoping for. Now, see if you can design a nice `for` loop to perform another `nperm-1` of these permutations and fill in the rest of the signature matrix, `Msig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can estimate the Jaccard similarity of (for example) Anya and Bahati as the proportion of the entries in the signature matrix in which the two agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Msig[:,0]==Msig[:,1])/nperm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the true value (from actually computing Jaccard similarity) is 0.5. Not too shabby! Here are all the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sum(Msig[:,0]==Msig[:,k])/nperm for k in range(len(dfC.columns))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:  Minhashing by hashing\n",
    "\n",
    "Now let's actually do for-real minhashing via hash functions. Again, instead of actually permuting our rows and constructing `dfPerm` above, we can simulate the effect of permuting the rows by just applying a hash function to our rows. \n",
    "\n",
    "We can use a *universal hash* function, of the form\n",
    "$$h(k) = (Ak+B) \\bmod{N}$$\n",
    "where $A$ and $B$ are random integers, and $N$ is the number of bins. Generally, choosing $N$ to be prime and (much) greater than the number of rows in the original matrix will minimize the odds of a collision. Here, $k$ represents the original row number within the characteristic matrix, and $h(k)$ represents the permuted row number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1:  pick hash functions\n",
    "\n",
    "# number of hash functions\n",
    "nhash = 10\n",
    "\n",
    "# use the \"universal hash\":  (a*x+b) mod p, where a, b are random ints and p > N (= 10 here) is prime\n",
    "np.random.seed(4022)\n",
    "Ahash = np.random.choice(range(0,10000), size=nhash)\n",
    "Bhash = np.random.choice(range(0,10000), size=nhash)\n",
    "Phash = 23\n",
    "\n",
    "# STEP 2:  initialize signature matrix to all infinities\n",
    "\n",
    "# initialize the signature matrix\n",
    "Msig = np.full([nhash, len(dfC.columns)], fill_value=np.inf)\n",
    "\n",
    "# fill in the signature matrix:\n",
    "\n",
    "# For each row of the characteristic matrix... \n",
    "hash_vals = [0]*nhash # initialize\n",
    "for r in range(len(dfC)):\n",
    "    # STEP 3:  Compute hash values (~permuted row numbers) for that row under each hash function\n",
    "    for h in range(nhash):\n",
    "        hash_vals[h] = (Ahash[h]*r + Bhash[h])%Phash\n",
    "    # STEP 4:  For each column, if there is a 0, do nothing...\n",
    "    for c in range(len(dfC.columns)):\n",
    "        # ... but if there is a 1, replace signature matrix element in that column for each hash fcn \n",
    "        # with the minimum of the hash value in this row, and the current signature matrix element\n",
    "        if dfC.iloc[r,c]==1:\n",
    "            for h in range(nhash):\n",
    "                if hash_vals[h] < Msig[h,c]:\n",
    "                    Msig[h,c] = hash_vals[h]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can estimate the similarities same as before with permutations, as the number of rows in which two columns agree. So our estimate of the sim(Anya, Bahati) is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Msig[:,0]==Msig[:,1])/nhash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOOF. That doesn't look very good. But keep in mind we only did 10 hash functions. Instead, let's kick this up to 1000, in increments of 10. Then we can see how our estimates converge on the true value of 0.5. We're going to want to compute the signature matrix `Msig` a whole bunch of times, so we better write a function to do the heavy lifting for us, for we are lazy/smart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minhash(nhash, dfC):\n",
    "    '''\n",
    "    Takes a number of hash functions to use (nhash) and characteristic matrix (dfC)\n",
    "    '''\n",
    "    # use the \"universal hash\":  (a*x+b) mod p, where a, b are random ints and p > N (= 10 here) is prime\n",
    "    np.random.seed(4022)\n",
    "    Ahash = np.random.choice(range(0,10000), size=nhash)\n",
    "    Bhash = np.random.choice(range(0,10000), size=nhash)\n",
    "    Phash = 23\n",
    "\n",
    "    # STEP 2:  initialize signature matrix to all infinities\n",
    "\n",
    "    # initialize the signature matrix\n",
    "    Msig = np.full([nhash, len(dfC.columns)], fill_value=np.inf)\n",
    "\n",
    "    # fill in the signature matrix:\n",
    "\n",
    "    # For each row of the characteristic matrix... \n",
    "    hash_vals = [0]*nhash # initialize\n",
    "    for r in range(len(dfC)):\n",
    "        # STEP 3:  Compute hash values (~permuted row numbers) for that row under each hash function\n",
    "        for h in range(nhash):\n",
    "            hash_vals[h] = (Ahash[h]*r + Bhash[h])%Phash\n",
    "        # STEP 4:  For each column, if there is a 0, do nothing...\n",
    "        for c in range(len(dfC.columns)):\n",
    "            # ... but if there is a 1, replace signature matrix element in that column for each hash fcn \n",
    "            # with the minimum of the hash value in this row, and the current signature matrix element\n",
    "            if dfC.iloc[r,c]==1:\n",
    "                for h in range(nhash):\n",
    "                    if hash_vals[h] < Msig[h,c]:\n",
    "                        Msig[h,c] = hash_vals[h]\n",
    "    return Msig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can lay out our grid of numbers of hash functions to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhash_trials = np.arange(10, 1010, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And before we get crazy, we should test our function with a known case of `nhash=10`. Note that our function from above set the random seed within the function, so we should end up with the same result as long as we didn't screw anything up. Let's see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Msig_tmp = minhash(10, dfC)\n",
    "sum(Msig_tmp[:,0]==Msig_tmp[:,1])/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yehoot! It matches! Now, armed with tons of unearned confidence, we march on. We just want to save the estimated similarity between Anya and Bahati for each number of hash functions used. Write a nice `for` loop or list comprehension (if you're feeling fancy!) to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can make a plot of the number of hash functions used (x-axis) against the estimated similarity between Anya and Bahati. Keep in mind that if you called the array-like object something creative (anything besides `sims`) for the plotting cell to work below, you'll need to modify the cell directly below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as `sims` whatever you called the similarities\n",
    "sims = sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7,5))\n",
    "plt.plot(nhash_trials, sims, color=\"steelblue\")\n",
    "plt.xlabel(\"number of hash functions\")\n",
    "plt.ylabel(\"estimated similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
